{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BertForSequenceClassification, DistilBertForSequenceClassification, RobertaForSequenceClassification, XLNetForSequenceClassification,BertTokenizer, DistilBertTokenizer, RobertaTokenizer, XLNetTokenizer\n",
    "import alpaca_trade_api as tradeapi\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, GRU, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber, LogCosh\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_log_error, r2_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Bloomberg Close Price</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Volume:Y-5</th>\n",
       "      <th>Volume:Y-4</th>\n",
       "      <th>Volume:Y-3</th>\n",
       "      <th>Volume:Y-2</th>\n",
       "      <th>Volume:Y-1</th>\n",
       "      <th>...</th>\n",
       "      <th>High Px:Y-4</th>\n",
       "      <th>High Px:Y-3</th>\n",
       "      <th>High Px:Y-2</th>\n",
       "      <th>High Px:Y-1</th>\n",
       "      <th>High Px:D-1</th>\n",
       "      <th>Open Px:Y-5</th>\n",
       "      <th>Open Px:Y-4</th>\n",
       "      <th>Open Px:Y-3</th>\n",
       "      <th>Open Px:Y-2</th>\n",
       "      <th>Open Px:Y-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLOYDSME IB Equity</td>\n",
       "      <td>Lloyds Metals &amp; Energy Ltd</td>\n",
       "      <td>576.05</td>\n",
       "      <td>576.05</td>\n",
       "      <td>True</td>\n",
       "      <td>40477.0</td>\n",
       "      <td>11641.0</td>\n",
       "      <td>127467.0</td>\n",
       "      <td>557635.0</td>\n",
       "      <td>125063.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>11.55</td>\n",
       "      <td>52.900002</td>\n",
       "      <td>147.649994</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>13.65</td>\n",
       "      <td>8.71</td>\n",
       "      <td>11.1</td>\n",
       "      <td>52.900002</td>\n",
       "      <td>146.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAZDOCKS IB Equity</td>\n",
       "      <td>Mazagon Dock Shipbuilders Ltd</td>\n",
       "      <td>1955.45</td>\n",
       "      <td>1955.45</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1239257.0</td>\n",
       "      <td>216111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>274.100006</td>\n",
       "      <td>277.850006</td>\n",
       "      <td>1957.800049</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.100006</td>\n",
       "      <td>272.700012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ticker                           Name    Price  \\\n",
       "0  LLOYDSME IB Equity     Lloyds Metals & Energy Ltd   576.05   \n",
       "1  MAZDOCKS IB Equity  Mazagon Dock Shipbuilders Ltd  1955.45   \n",
       "\n",
       "   Bloomberg Close Price  Comparison  Volume:Y-5  Volume:Y-4  Volume:Y-3  \\\n",
       "0                 576.05        True     40477.0     11641.0    127467.0   \n",
       "1                1955.45        True         0.0         0.0         0.0   \n",
       "\n",
       "   Volume:Y-2  Volume:Y-1  ...  High Px:Y-4  High Px:Y-3  High Px:Y-2  \\\n",
       "0    557635.0    125063.0  ...          8.8        11.55    52.900002   \n",
       "1   1239257.0    216111.0  ...          0.0         0.00   274.100006   \n",
       "\n",
       "   High Px:Y-1  High Px:D-1  Open Px:Y-5  Open Px:Y-4  Open Px:Y-3  \\\n",
       "0   147.649994   580.000000        13.65         8.71         11.1   \n",
       "1   277.850006  1957.800049         0.00         0.00          0.0   \n",
       "\n",
       "   Open Px:Y-2  Open Px:Y-1  \n",
       "0    52.900002   146.899994  \n",
       "1   274.100006   272.700012  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"BSE500 as of Jul 24 20231_gyluxqnl.xlsx\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goeld\\AppData\\Local\\Temp\\ipykernel_44996\\3552615449.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1.fillna(data1.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "features = ['Price', 'Volume:Y-5', 'Volume:Y-4', 'Volume:Y-3', 'Volume:Y-2', 'Volume:Y-1', \n",
    "            'Total Return:Y-4', 'Total Return:Y-3', 'Total Return:Y-2', \n",
    "            'Total Return:Y-1', 'Total Return:Y-5',  \n",
    "            'Low Px:Y-5', 'Low Px:Y-4', 'Low Px:Y-3', 'Low Px:Y-2', 'Low Px:Y-1', \n",
    "            'High Px:Y-5', 'High Px:Y-4', 'High Px:Y-3', 'High Px:Y-2', 'High Px:Y-1', \n",
    "            'Bloomberg Close Price', 'Open Px:Y-5', 'Open Px:Y-4', 'Open Px:Y-3', 'Open Px:Y-2', 'Open Px:Y-1']\n",
    "\n",
    "data1 = data[features]\n",
    "\n",
    "# Handle missing values (example: fill with median)\n",
    "data1.fillna(data1.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Price', 'Volume:Y-5', 'Volume:Y-4', 'Volume:Y-3', 'Volume:Y-2',\n",
       "       'Volume:Y-1', 'Total Return:Y-4', 'Total Return:Y-3',\n",
       "       'Total Return:Y-2', 'Total Return:Y-1', 'Total Return:Y-5',\n",
       "       'Low Px:Y-5', 'Low Px:Y-4', 'Low Px:Y-3', 'Low Px:Y-2', 'Low Px:Y-1',\n",
       "       'High Px:Y-5', 'High Px:Y-4', 'High Px:Y-3', 'High Px:Y-2',\n",
       "       'High Px:Y-1', 'Bloomberg Close Price', 'Open Px:Y-5', 'Open Px:Y-4',\n",
       "       'Open Px:Y-3', 'Open Px:Y-2', 'Open Px:Y-1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Volume:Y-5', 'Volume:Y-4', 'Volume:Y-3', 'Volume:Y-2', 'Volume:Y-1', 'Volume:D-1',\n",
    "          'Total Return:Y-4', 'Total Return:Y-3', 'Total Return:Y-2', 'Total Return:Y-1', 'Total Return:Y-5', 'Total Return:D-1',\n",
    "          'Low Px:Y-5', 'Low Px:Y-4', 'Low Px:Y-3', 'Low Px:Y-2', 'Low Px:Y-1', 'Low Px:D-1',\n",
    "          'High Px:Y-5', 'High Px:Y-4', 'High Px:Y-3', 'High Px:Y-2', 'High Px:Y-1', 'High Px:D-1',\n",
    "          'Open Px:Y-5', 'Open Px:Y-4', 'Open Px:Y-3', 'Open Px:Y-2', 'Open Px:Y-1', \"Bloomberg Close Price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = data[['Volume:Y-5', 'Volume:Y-4', 'Volume:Y-3', 'Volume:Y-2', 'Volume:Y-1',\n",
    "          'Total Return:Y-4', 'Total Return:Y-3', 'Total Return:Y-2', 'Total Return:Y-1', 'Total Return:Y-5', \n",
    "          'Low Px:Y-5', 'Low Px:Y-4', 'Low Px:Y-3', 'Low Px:Y-2', 'Low Px:Y-1', 'Low Px:D-1',\n",
    "          'High Px:Y-5', 'High Px:Y-4', 'High Px:Y-3', 'High Px:Y-2', 'High Px:Y-1', \n",
    "          'Open Px:Y-5', 'Open Px:Y-4', 'Open Px:Y-3', 'Open Px:Y-2', 'Open Px:Y-1']]\n",
    "\n",
    "y = data['Bloomberg Close Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       F-Value       P-Value\n",
      "Volume:Y-5        5.240413e+01  5.636527e-51\n",
      "Volume:Y-4        7.775297e+01  3.786011e-49\n",
      "Volume:Y-3        1.223694e+02  6.248265e-46\n",
      "Volume:Y-2        2.254353e+02  2.213627e-29\n",
      "Volume:Y-1        4.668531e+02  4.454512e-08\n",
      "Total Return:Y-4  7.775297e+01  3.786011e-49\n",
      "Total Return:Y-3  1.223694e+02  6.248265e-46\n",
      "Total Return:Y-2  2.254353e+02  2.213627e-29\n",
      "Total Return:Y-1  4.668531e+02  4.454512e-08\n",
      "Total Return:Y-5  5.240413e+01  5.636527e-51\n",
      "Low Px:Y-5        5.112348e+01  2.210939e-52\n",
      "Low Px:Y-4        8.724872e+01  7.460375e-56\n",
      "Low Px:Y-3        1.126601e+02  1.073386e-49\n",
      "Low Px:Y-2        2.948690e+02  3.733241e-40\n",
      "Low Px:Y-1        7.318693e+02  7.539734e-15\n",
      "Low Px:D-1        5.110447e+07  3.788485e-12\n",
      "High Px:Y-5       5.664958e+01  1.198025e-56\n",
      "High Px:Y-4       7.849396e+01  6.695004e-55\n",
      "High Px:Y-3       1.378993e+02  3.902411e-53\n",
      "High Px:Y-2       2.002345e+02  3.347687e-34\n",
      "High Px:Y-1       2.647955e+02  1.998726e-12\n",
      "Open Px:Y-5       5.040299e+01  3.881138e-55\n",
      "Open Px:Y-4       8.578061e+01  2.624896e-56\n",
      "Open Px:Y-3       1.237859e+02  1.022010e-51\n",
      "Open Px:Y-2       2.429556e+02  1.152760e-35\n",
      "Open Px:Y-1       1.104298e+03  5.027258e-25\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# ANOVA test for each feature\n",
    "anova_results = {}\n",
    "for col in X.columns:\n",
    "    groups = [y[data[col] == val] for val in data[col].unique()]\n",
    "    f_val, p_val = stats.f_oneway(*groups)\n",
    "    anova_results[col] = {'F-Value': f_val, 'P-Value': p_val}\n",
    "\n",
    "anova_df = pd.DataFrame(anova_results).T\n",
    "print(anova_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Discretize y (Bloomberg Close Price):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Chi2 Score        P-value\n",
      "0         Volume:Y-5   54.227970   4.714854e-11\n",
      "1         Volume:Y-4   52.816287   9.310405e-11\n",
      "2         Volume:Y-3   76.044208   1.198176e-15\n",
      "3         Volume:Y-2  136.113762   1.916368e-28\n",
      "4         Volume:Y-1  133.108960   8.421911e-28\n",
      "5   Total Return:Y-4   25.308911   4.360278e-05\n",
      "6   Total Return:Y-3    5.023812   2.848630e-01\n",
      "7   Total Return:Y-2    8.720495   6.847837e-02\n",
      "8   Total Return:Y-1   10.824257   2.861176e-02\n",
      "9   Total Return:Y-5   39.608020   5.216447e-08\n",
      "10        Low Px:Y-5  187.624802   1.716552e-39\n",
      "11        Low Px:Y-4  236.214158   6.062961e-50\n",
      "12        Low Px:Y-3  279.833762   2.420102e-59\n",
      "13        Low Px:Y-2  360.036584   1.193360e-76\n",
      "14        Low Px:Y-1  437.713168   1.967581e-93\n",
      "15        Low Px:D-1  488.555941  2.000249e-104\n",
      "16       High Px:Y-5  182.272772   2.423269e-38\n",
      "17       High Px:Y-4  238.358663   2.093648e-50\n",
      "18       High Px:Y-3  279.833762   2.420102e-59\n",
      "19       High Px:Y-2  359.406584   1.632367e-76\n",
      "20       High Px:Y-1  436.781931   3.127718e-93\n",
      "21       Open Px:Y-5  187.624802   1.716552e-39\n",
      "22       Open Px:Y-4  237.701287   2.900425e-50\n",
      "23       Open Px:Y-3  280.901089   1.424650e-59\n",
      "24       Open Px:Y-2  360.346584   1.022887e-76\n",
      "25       Open Px:Y-1  437.713168   1.967581e-93\n"
     ]
    }
   ],
   "source": [
    "# Discretize y (Bloomberg Close Price) into quantiles\n",
    "y_discrete = pd.qcut(y.rank(method='first'), q=5, labels=False)\n",
    "\n",
    "# Chi-square test\n",
    "chi_scores, p_values = chi2(X_discrete, y_discrete)\n",
    "chi_square_df = pd.DataFrame({'Feature': X.columns, 'Chi2 Score': chi_scores, 'P-value': p_values})\n",
    "\n",
    "print(chi_square_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ensure Non-Negative Values in Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Chi2 Score        P-value\n",
      "0         Volume:Y-5   54.227970   4.714854e-11\n",
      "1         Volume:Y-4   52.816287   9.310405e-11\n",
      "2         Volume:Y-3   76.044208   1.198176e-15\n",
      "3         Volume:Y-2  136.113762   1.916368e-28\n",
      "4         Volume:Y-1  133.108960   8.421911e-28\n",
      "5   Total Return:Y-4   25.308911   4.360278e-05\n",
      "6   Total Return:Y-3    5.023812   2.848630e-01\n",
      "7   Total Return:Y-2    8.720495   6.847837e-02\n",
      "8   Total Return:Y-1   10.824257   2.861176e-02\n",
      "9   Total Return:Y-5   39.608020   5.216447e-08\n",
      "10        Low Px:Y-5  187.624802   1.716552e-39\n",
      "11        Low Px:Y-4  236.214158   6.062961e-50\n",
      "12        Low Px:Y-3  279.833762   2.420102e-59\n",
      "13        Low Px:Y-2  360.036584   1.193360e-76\n",
      "14        Low Px:Y-1  437.713168   1.967581e-93\n",
      "15        Low Px:D-1  488.555941  2.000249e-104\n",
      "16       High Px:Y-5  182.272772   2.423269e-38\n",
      "17       High Px:Y-4  238.358663   2.093648e-50\n",
      "18       High Px:Y-3  279.833762   2.420102e-59\n",
      "19       High Px:Y-2  359.406584   1.632367e-76\n",
      "20       High Px:Y-1  436.781931   3.127718e-93\n",
      "21       Open Px:Y-5  187.624802   1.716552e-39\n",
      "22       Open Px:Y-4  237.701287   2.900425e-50\n",
      "23       Open Px:Y-3  280.901089   1.424650e-59\n",
      "24       Open Px:Y-2  360.346584   1.022887e-76\n",
      "25       Open Px:Y-1  437.713168   1.967581e-93\n"
     ]
    }
   ],
   "source": [
    "# Ensure non-negative values in X_discrete\n",
    "X_discrete = X.apply(lambda x: pd.qcut(x.rank(method='first'), q=5, labels=False))\n",
    "X_discrete = X_discrete - X_discrete.min().min()  # Shift to make non-negative if necessary\n",
    "\n",
    "# Chi-square test\n",
    "chi_scores, p_values = chi2(X_discrete, y_discrete)\n",
    "chi_square_df = pd.DataFrame({'Feature': X.columns, 'Chi2 Score': chi_scores, 'P-value': p_values})\n",
    "\n",
    "print(chi_square_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_excel(\"BSE500 as of Jul 24 20231_gyluxqnl.xlsx\")\n",
    "\n",
    "# Define features and target\n",
    "X = data[['Volume:Y-5', 'Volume:Y-4', 'Volume:Y-3', 'Volume:Y-2', 'Volume:Y-1', \n",
    "          'Total Return:Y-4', 'Total Return:Y-3', 'Total Return:Y-2', 'Total Return:Y-1', 'Total Return:Y-5', \n",
    "          'Low Px:Y-5', 'Low Px:Y-4', 'Low Px:Y-3', 'Low Px:Y-2', 'Low Px:Y-1', \n",
    "          'High Px:Y-5', 'High Px:Y-4', 'High Px:Y-3', 'High Px:Y-2', 'High Px:Y-1', \n",
    "          'Open Px:Y-5', 'Open Px:Y-4', 'Open Px:Y-3', 'Open Px:Y-2', 'Open Px:Y-1']]\n",
    "y = data['Bloomberg Close Price']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definitions and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goeld\\anaconda3\\envs\\assistant\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 51679988.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m 9/13\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 58113416.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goeld\\anaconda3\\envs\\assistant\\lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 54358440.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 38488744.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 34565844.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 22312138.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 42275096.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 40188492.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 46583252.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 22878738.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 57010512.0000\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goeld\\anaconda3\\envs\\assistant\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 23237952.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m 7/13\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 25172110.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goeld\\anaconda3\\envs\\assistant\\lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 27579928.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 44385700.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 30158380.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 27880002.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 59986296.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 61114912.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 56202080.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 19835428.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 50239132.0000\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goeld\\anaconda3\\envs\\assistant\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 59770776.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m 9/13\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 31769346.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goeld\\anaconda3\\envs\\assistant\\lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 35736904.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22424914.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24173834.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 36534048.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25609868.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 74804952.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 46481644.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 37584748.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 93370504.0000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025C6DF98C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 362ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025C6DF98C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step\n"
     ]
    }
   ],
   "source": [
    "# Model Definitions\n",
    "\n",
    "# Adjust ModelCheckpoint for LSTM, GRU, and RNN models\n",
    "lstm_checkpoint = ModelCheckpoint('lstm_model.keras', save_best_only=True)\n",
    "gru_checkpoint = ModelCheckpoint('gru_model.keras', save_best_only=True)\n",
    "rnn_checkpoint = ModelCheckpoint('rnn_model.keras', save_best_only=True)\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(GRU(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def create_rnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))  # Simple RNN layer\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "# SVM Regressor\n",
    "svm_model = SVR()\n",
    "\n",
    "# Define and Train Models\n",
    "# Linear Regression\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# LSTM\n",
    "lstm_model = create_lstm_model((X_train.shape[1], 1))\n",
    "lstm_model.fit(X_train.reshape(X_train.shape[0], X_train.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=1, callbacks=[ModelCheckpoint('lstm_model.keras', save_best_only=True)])\n",
    "\n",
    "# GRU\n",
    "gru_model = create_gru_model((X_train.shape[1], 1))\n",
    "gru_model.fit(X_train.reshape(X_train.shape[0], X_train.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=1, callbacks=[ModelCheckpoint('gru_model.keras', save_best_only=True)])\n",
    "\n",
    "# RNN\n",
    "rnn_model = create_rnn_model((X_train.shape[1], 1))\n",
    "rnn_model.fit(X_train.reshape(X_train.shape[0], X_train.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=1, callbacks=[ModelCheckpoint('rnn_model.keras', save_best_only=True)])\n",
    "\n",
    "# Predictions\n",
    "y_pred_lstm = lstm_model.predict(X_test.reshape(X_test.shape[0], X_test.shape[1], 1))\n",
    "y_pred_gru = gru_model.predict(X_test.reshape(X_test.shape[0], X_test.shape[1], 1))\n",
    "y_pred_rnn = rnn_model.predict(X_test.reshape(X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Ensure inputs are numpy arrays\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate Huber Loss\n",
    "    delta = 1.0\n",
    "    abs_diff = np.abs(y_true - y_pred)\n",
    "    huber_loss = np.mean(np.where(abs_diff < delta, 0.5 * abs_diff**2, delta * abs_diff - 0.5 * delta))\n",
    "    \n",
    "    # Calculate Log-Cosh Loss\n",
    "    log_cosh_loss = np.mean(np.log(np.cosh(y_pred - y_true)))\n",
    "    \n",
    "    return mse, mae, r2, huber_loss, log_cosh_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test: (101,)\n",
      "Shape of y_pred_rf: (101,)\n",
      "Shape of y_pred_xgb: (101,)\n",
      "Shape of y_pred_lstm: (101, 1)\n",
      "Shape of y_pred_gru: (101, 1)\n",
      "Shape of y_pred_rnn: (101, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Shape of y_pred_rf:\", y_pred_rf.shape)\n",
    "print(\"Shape of y_pred_xgb:\", y_pred_xgb.shape)\n",
    "print(\"Shape of y_pred_lstm:\", y_pred_lstm.shape)\n",
    "print(\"Shape of y_pred_gru:\", y_pred_gru.shape)\n",
    "print(\"Shape of y_pred_rnn:\", y_pred_rnn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RF: (38647.0866610727, 113.00433930390295, 0.9772798824772148, 112.50433930390295, inf)\n",
      "Metrics for XGB: (35335.17861676153, 114.72583152903186, 0.9792269099634341, 114.22583152903186, inf)\n",
      "Metrics for LSTM: (2751828.3278229544, 1025.0956812754716, -0.6177639354544733, 1024.5984778679233, inf)\n",
      "Metrics for GRU: (2752307.045308873, 1025.3292521675037, -0.6180453672124651, 1024.8305803168726, inf)\n",
      "Metrics for RNN: (2752556.3868593685, 1025.4507036492378, -0.6181919518536374, 1024.9514823197217, inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goeld\\AppData\\Local\\Temp\\ipykernel_44996\\1805134145.py:18: RuntimeWarning: overflow encountered in cosh\n",
      "  log_cosh_loss = np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "C:\\Users\\goeld\\AppData\\Local\\Temp\\ipykernel_44996\\1805134145.py:18: RuntimeWarning: overflow encountered in cosh\n",
      "  log_cosh_loss = np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "C:\\Users\\goeld\\AppData\\Local\\Temp\\ipykernel_44996\\1805134145.py:18: RuntimeWarning: overflow encountered in cosh\n",
      "  log_cosh_loss = np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "C:\\Users\\goeld\\AppData\\Local\\Temp\\ipykernel_44996\\1805134145.py:18: RuntimeWarning: overflow encountered in cosh\n",
      "  log_cosh_loss = np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "C:\\Users\\goeld\\AppData\\Local\\Temp\\ipykernel_44996\\1805134145.py:18: RuntimeWarning: overflow encountered in cosh\n",
      "  log_cosh_loss = np.mean(np.log(np.cosh(y_pred - y_true)))\n"
     ]
    }
   ],
   "source": [
    "# Example calculations\n",
    "metrics_rf = calculate_metrics(y_test, y_pred_rf)\n",
    "metrics_xgb = calculate_metrics(y_test, y_pred_xgb)\n",
    "metrics_lstm = calculate_metrics(y_test, y_pred_lstm)\n",
    "metrics_gru = calculate_metrics(y_test, y_pred_gru)\n",
    "metrics_rnn = calculate_metrics(y_test, y_pred_rnn)\n",
    "\n",
    "print(\"Metrics for RF:\", metrics_rf)\n",
    "print(\"Metrics for XGB:\", metrics_xgb)\n",
    "print(\"Metrics for LSTM:\", metrics_lstm)\n",
    "print(\"Metrics for GRU:\", metrics_gru)\n",
    "print(\"Metrics for RNN:\", metrics_rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
